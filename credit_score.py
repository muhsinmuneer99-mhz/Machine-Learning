# -*- coding: utf-8 -*-
"""Credit_Score.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dYWe6hcyWMKsU_DCq204iYpH-Q0Bdc-p

Banks and credit card companies calculate your credit score to determine your creditworthiness. It helps banks and credit card companies immediately to issue loans to customers with good creditworthiness. Today banks and credit card companies use Machine Learning algorithms to classify all the customers in their database based on their credit history.

I will take you through the task of credit score classification with Machine Learning using Python.

There are three credit scores that banks and credit card companies use to label their customers:

Good
Standard
Poor
A person with a good credit score will get loans from any bank and financial institution. For the task of Credit Score Classification, we need a labelled dataset with credit scores.

In the section below, I will take you through the task of credit score classification with Machine Learning using Python.
"""

import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import plotly.io as pio
pio.templates.default = "plotly_white"
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report,accuracy_score,ConfusionMatrixDisplay
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import RandomizedSearchCV
from imblearn.over_sampling import SMOTE

df=pd.read_csv('/content/sample_data/mnist_test.csv')
df.head()

df.shape

df.columns

df.info()

df.describe()

df.isna().sum()

df['Credit_Score'].value_counts()

# visualize it
sns.countplot(df['Credit_Score'])

df.drop(['Customer_ID',],axis=1,inplace=True)
df.drop(['ID','Age','Name','SSN','Month'],axis=1,inplace=True)

df_cat=[x for x in df.columns if df[x].dtype=='O']
df_cat

fig=px.box(df,x='Occupation',color='Credit_Score',
           title='Credit Scores Based on Occupation',
           color_discrete_map={'Poor':'red','Standard':'yellow','Good':'green'})

fig.show()

df_num=[x for x in df.columns if(df[x].dtype!='O') & (x not in ['Credit_Score'])]
df_num

"""There’s not much difference in the credit scores of all occupations mentioned in the data. Now let’s explore whether the Annual Income of the person impacts your credit scores or not:"""

fig=px.box(df,x='Credit_Score',y='Annual_Income',color='Credit_Score',
           title='Credit Scores Based on Annual Income',
           color_discrete_map={'Poor':'red','Standard':'yellow','Good':'green'})
fig.update_traces(quartilemethod="exclusive")
fig.show()

"""According to the above visualization, the more you earn annually, the better your credit score is.
Now let’s see if having more bank accounts impacts credit scores or not:
"""

fig=px.box(df,x='Credit_Score',y='Num_Bank_Accounts',color='Credit_Score',
           title='Credit Scores Based on Number of Bank Accounts',
           color_discrete_map={'Poor':'red','Standard':'yellow','Good':'green'})
fig.update_traces(quartilemethod="exclusive")
fig.show()

"""Maintaining more than five accounts is not good for having a good credit score. A person should have 2 – 3 bank accounts only. So having more bank accounts doesn’t positively impact credit scores. Now let’s see the impact on credit scores based on the number of credit cards you have:"""

fig=px.box(df,x='Credit_Score',y='Num_Credit_Card',color='Credit_Score',
           title='Credit Scores Based on Number of Credit Cards',
           color_discrete_map={'Poor':'red','Standard':'yellow','Good':'green'})
fig.update_traces(quartilemethod="exclusive")
fig.show()

"""Just like the number of bank accounts, having more credit cards will not positively impact your credit scores. Having 3 – 5 credit cards is good for your credit score.


"""

fig=px.box(df,x='Credit_Score',y='Num_of_Loan',color='Credit_Score',
           title='Credit Scores Based on Number of loans taken by the person',
           color_discrete_map={'Poor':'red','Standard':'yellow','Good':'green'})
fig.update_traces(quartilemethod="exclusive")
fig.show()

"""To have a good credit score, you should not take more than 1 – 3 loans at a time. Having more than three loans at a time will negatively impact your credit scores."""

fig=px.box(df,x='Credit_Score',y='Delay_from_due_date',color='Credit_Score',
           title='Credit Scores Based on Average number of days Delayed',
           color_discrete_map={'Poor':'red','Standard':'yellow','Good':'green'})
fig.update_traces(quartilemethod="exclusive")
fig.show()

"""So you can delay your credit card payment 5 – 14 days from the due date. Delaying your payments for more than 17 days from the due date will impact your credit scores negatively"""

df.head()

# convert all non-numeric into numeric
from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()

for x in df.columns:
  if df[x].dtype==np.number:
    continue
  df[x]=le.fit_transform(df[x])

df.head()   # here all columns are in numeric data

df.info()  # so all in integer and float

# x and y seperation
x=df.iloc[:,:-1].values
y=df.iloc[:,-1].values

# scale the data
from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()
x=scaler.fit_transform(x)
x

df.shape

"""**PCA(Principle Component Analysis)**
It is reduction technique that transforms high dimensional dataset into a new lower-dimensional dataset.At the same time,presrving the maximum amount of information from the original data
"""

pca=PCA()
pca.fit(x)

pca.explained_variance_ratio_

# scree plot
fig,ax=plt.subplots()
xi=np.arange(1,x.shape[1]+1,1)
yi=np.cumsum(pca.explained_variance_ratio_)
plt.plot(xi,yi,marker='o',linestyle='--',color='b')
plt.xlabel('Number of Components')
plt.xticks(xi)
plt.ylabel('Cumulative variance (%)')
plt.title('Scree Plot')
ax.set_ylim([0.70,1.01])
plt.axhline(y=0.95,color='r',linestyle='--')
ax.grid('both')
plt.xticks(rotation=90)
plt.show()

pca=PCA(n_components=0.95,random_state=42)
pca.fit(x)
x_pca=pca.transform(x)
print('Shape of x before PCA:',x.shape)
print('Shape of x after PCA:',x_pca.shape)

# train test split
xtrain,xtest,ytrain,ytest=train_test_split(x_pca,y,test_size=0.30,random_state=42)
xtrain
xtest
ytrain
ytest

df['Credit_Score'].value_counts()

"""**Creating Different Models Using Imbalanced Dataset**

**KNN**
"""

model=KNeighborsClassifier(n_neighbors=5)
model.fit(xtrain,ytrain)
ypredknn=model.predict(xtest)

print(classification_report(ytest,ypredknn))
print(ConfusionMatrixDisplay.from_predictions(ypredknn,ytest))

"""**Logistic Regression**"""

#lr
lr=LogisticRegression()
lr.fit(xtrain,ytrain)

ypredlr=lr.predict(xtest)

from sklearn.metrics._plot.confusion_matrix import ConfusionMatrixDisplay
print(classification_report(ypredlr,ytest))
print(ConfusionMatrixDisplay.from_predictions(ypredlr,ytest))

"""**Naive Bayes**"""

nb=GaussianNB()
nb.fit(xtrain,ytrain)

yprednb=nb.predict(xtest)
yprednb

print(classification_report(yprednb,ytest))
print(ConfusionMatrixDisplay.from_predictions(yprednb,ytest))

"""**Decision Tree(gini)**"""

tree=DecisionTreeClassifier()
tree.fit(xtrain,ytrain)

ypredtree=tree.predict(xtest)

print(classification_report(ypredtree,ytest))
print(ConfusionMatrixDisplay.from_predictions(ypredtree,ytest))

"""**Decision Tree(entropy)**"""

tretp=DecisionTreeClassifier(criterion='entropy')
tretp.fit(xtrain,ytrain)

ypredtree2=tretp.predict(xtest)

print(classification_report(ypredtree2,ytest))
print(ConfusionMatrixDisplay.from_predictions(ypredtree2,ytest))

"""**Random Forest**"""

rfcl=RandomForestClassifier(max_depth=10,n_estimators=400)
rfcl.fit(xtrain,ytrain)

ypredrf=rfcl.predict(xtest)

print(classification_report(ypredrf,ytest))
print(ConfusionMatrixDisplay.from_predictions(ypredrf,ytest))

"""**Balancing Data  using smote**"""

# using oversampling technique smote
oversample=SMOTE()
xo,yo=oversample.fit_resample(x_pca,y)

xtrain_new,xtest_new,ytrain_new,ytest_new=train_test_split(xo,yo,test_size=0.20,random_state=42)

"""**KNN**"""

knn=KNeighborsClassifier(n_neighbors=5)
knn.fit(xtrain_new,ytrain_new)
y_predknnb=knn.predict(xtest_new)

print(classification_report(y_predknnb,ytest_new))
print(ConfusionMatrixDisplay.from_predictions(y_predknnb,ytest_new))

"""**Logistic Regression**"""

lr=LogisticRegression()
lr.fit(xtrain_new,ytrain_new)

ypred_lr=lr.predict(xtest_new)
ypred_lr

print(classification_report(ypred_lr,ytest_new))
print(ConfusionMatrixDisplay.from_predictions(ypred_lr,ytest_new))

"""**Naive Bayes**"""

nb=GaussianNB()
nb.fit(xtrain_new,ytrain_new)

ypred_nb=nb.predict(xtest_new)
ypred_nb

print(classification_report(ypred_nb,ytest_new))
print(ConfusionMatrixDisplay.from_predictions(ypred_nb,ytest_new))

"""**Decison Tree(gini)**"""

# dtree
tree=DecisionTreeClassifier()
tree.fit(xtrain_new,ytrain_new)

ypred_tree=tree.predict(xtest_new)

print(classification_report(ypred_tree,ytest_new))
print(ConfusionMatrixDisplay.from_predictions(ypred_tree,ytest_new))

"""**Decision Tree(entropy)**"""

tretp=DecisionTreeClassifier(criterion='entropy')
tretp.fit(xtrain_new,ytrain_new)

ypred_tree2=tretp.predict(xtest_new)

print(classification_report(ypred_tree2,ytest_new))
print(ConfusionMatrixDisplay.from_predictions(ypred_tree2,ytest_new))

"""**Random Forest**"""

#rf
rfcl=RandomForestClassifier(max_depth=10,n_estimators=400)
rfcl.fit(xtrain_new,ytrain_new)

ypred_rf=rfcl.predict(xtest_new)

print(classification_report(ypred_rf,ytest_new))
print(ConfusionMatrixDisplay.from_predictions(ypred_rf,ytest_new)

accuracy_df['Classifier']=['KNN','Logistic Regression','Naive Bayes','SVM','Decision Tree(gini)','Decision Tree(entropy)','Random Forest']
accuracy_df['Accuracy of Imbalanced Data']=[accuracy_score(ypredknn,ytest),accuracy_score(ypredlr,ytest),accuracy_score(yprednb,ytest),
                                            accuracy_score(ypredtree,ytest),accuracy_score(ypredtree2,ytest),
                                            accuracy_score(ypredrf,ytest)]
accuracy_df['Accuracy of Balanced Data']=[accuracy_score(y_predknnb,ytest_new),accuracy_score(ypred_lr,ytest_new),accuracy_score(ypred_nb,ytest_new),
                                          accuracy_score(ypred_tree,ytest_new),accuracy_score(ypred_tree2,ytest_new),
                                          accuracy_score(ypred_rf,ytest_new)]